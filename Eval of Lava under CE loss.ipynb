{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a22dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForQuestionAnswering were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {0: 'LABEL_0', 1: 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
      "Found cached dataset gigaword (/home/ruihan/.cache/huggingface/datasets/gigaword/default/1.2.0/ea83a8b819190acac5f2dae011fad51dccf269a0604ec5dd24795b64efb424b6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f6196f20104698ac2979e1fb9bc3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ruihan/.cache/huggingface/datasets/gigaword/default/1.2.0/ea83a8b819190acac5f2dae011fad51dccf269a0604ec5dd24795b64efb424b6/cache-6816d5b30b6eeb9a.arrow\n",
      "Loading cached processed dataset at /home/ruihan/.cache/huggingface/datasets/gigaword/default/1.2.0/ea83a8b819190acac5f2dae011fad51dccf269a0604ec5dd24795b64efb424b6/cache-6aeaeef7bff602c5.arrow\n",
      "Loading cached processed dataset at /home/ruihan/.cache/huggingface/datasets/gigaword/default/1.2.0/ea83a8b819190acac5f2dae011fad51dccf269a0604ec5dd24795b64efb424b6/cache-29041409e3286f61.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gigaword training examples: 3803957\n",
      "Number of gigaword validation examples: 189651\n",
      "Number of gigaword testing examples: 1951\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'input_texts', 'label_texts'],\n",
      "        num_rows: 3803957\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'input_texts', 'label_texts'],\n",
      "        num_rows: 189651\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'input_texts', 'label_texts'],\n",
      "        num_rows: 1951\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, TrainingArguments, Trainer, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "from lava import LavaModel\n",
    "model = LavaModel.from_lava_pretrained('roberta-base', 'facebook/bart-base')\n",
    "\n",
    "from utils.datasets_config import get_dataset\n",
    "\n",
    "dset = get_dataset('gigaword', 'facebook/bart-base')\n",
    "print(dset)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a5292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # evaluation_strategy = \"steps\",\n",
    "    output_dir= 'lava-ce',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    max_steps = 700_000,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=5_000,\n",
    "    save_total_limit=20,\n",
    "    prediction_loss_only=True,\n",
    "    dataloader_num_workers=4,\n",
    "    # learning_rate=3e-4,\n",
    "    # logging_steps = 5,\n",
    "    # eval_steps = 5,\n",
    "    # metric_for_best_model = 'f1',\n",
    "    # load_best_model_at_end=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105e4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    batch = ({k: torch.nn.utils.rnn.pad_sequence([dic[k] for dic in batch], batch_first=True, padding_value=1) for k in batch[0]})\n",
    "    # batch['input_ids'][batch['input_ids'] == -100] = 1\n",
    "    batch['attention_mask'] = (batch['input_ids'] != 1).long()\n",
    "    batch['labels'][batch['labels']==1] = -100\n",
    "#     batch['labels'] = torch.nn.functional.pad(batch['labels'], (0, batch['input_ids'].shape[1] - batch['labels'].shape[1], 0, 0), 'constant', 1)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc31fb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/ruihan/.cache/huggingface/datasets/gigaword/default/1.2.0/ea83a8b819190acac5f2dae011fad51dccf269a0604ec5dd24795b64efb424b6/cache-aac49639e82619d5.arrow\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = dset['train'].shuffle(1234),\n",
    "    eval_dataset = dset['validation'].shard(300, 1),\n",
    "    data_collator = collate,\n",
    "    # compute_metrics = lambda x: print(x),\n",
    "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=7)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d2856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from /home/ruihan/Downloads/or/seq2seq-ngram/lava-ce/checkpoint-45000.\n"
     ]
    }
   ],
   "source": [
    "trainer._load_from_checkpoint('/home/ruihan/Downloads/or/seq2seq-ngram/lava-ce/checkpoint-45000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff0f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `LavaModel.forward` and have been ignored: label_texts, input_texts. If label_texts, input_texts are not expected by `LavaModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 633\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6419733762741089,\n",
       " 'eval_runtime': 5.3523,\n",
       " 'eval_samples_per_second': 118.267,\n",
       " 'eval_steps_per_second': 14.947}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9322d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/ruihan/.cache/huggingface/datasets/gigaword/default/1.2.0/ea83a8b819190acac5f2dae011fad51dccf269a0604ec5dd24795b64efb424b6/cache-cc3ae6613d45409b.arrow\n"
     ]
    }
   ],
   "source": [
    "d = next(iter(dset['train'].shard(300, 1).shuffle()))\n",
    "decoder_input_ids = (d['labels'] == 1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f727e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(\n",
    "    input_ids = d['input_ids'].cuda().unsqueeze(0),\n",
    "    attention_mask = d['attention_mask'].cuda().unsqueeze(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6658f8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,   397, 17419, 10409,    34,  4768,   690,    14,   169,   858,\n",
       "          4533,  6071,    40,    28,  1088,    11,     5, 10408, 16705,  2937,\n",
       "          2931,  1437,  1437,   511, 18898,  6116,    59,     5,  5955,  1437,\n",
       "           579,   499,    23,     5,   950,  1437,  1437,     2]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([    0, 33557,  9118,   708,     7,  1331,  4533,  6071,     2])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f296c16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   397, 17419, 10409,    34,  4768,   690,    14,   169,   858,\n",
       "          4533,  6071,    40,    28,  1088,    11,     5, 10408, 16705,  2937,\n",
       "          2931,  1437,  1437,   511, 18898,  6116,    59,     5,  5955,  1437,\n",
       "           579,   499,    23,     5,   950,  1437,  1437,     2,     0,   397,\n",
       "         17419, 10409,   293,   293,    14,  6071,  6071,    28,    28,    28,\n",
       "            28,    28, 16705,  2937, 16705,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.logits.argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f395cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>manchester united has dismissed reports that wayne rooney will be sold in the january transfer window   following rampant speculation about the striker  s future at the club  </s><s>manchester unitedeses thatoneyoney be be be be beuary transferuary</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(o.logits.argmax(2).tolist()[0], skip_special_tokens=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6382cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manchester united has dismissed reports that wayne rooney will be sold in the january transfer window   following rampant speculation about the striker  s future at the club  \n",
      "\n",
      "united denies plans to sell rooney\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(d['input_ids'], skip_special_tokens=True))\n",
    "print()\n",
    "print(tokenizer.decode(d['labels'], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a41ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3593, -2.8969, -3.9509, -3.8093, -3.8101, -3.9115, -3.8839, -3.6557,\n",
       "         -3.2314, -2.6915, -2.1503, -1.6781, -1.2829, -0.9393, -0.6404, -0.4126,\n",
       "         -0.2381, -0.0332,  0.1980,  0.4207,  0.6288,  0.8199,  0.9906,  1.1332,\n",
       "          1.2471,  1.3378,  1.4112,  1.4716,  1.5220,  1.5645,  1.6008,  1.6318,\n",
       "          1.6584,  1.6814,  1.7013,  1.7184,  1.7332,  1.7460]],\n",
       "       device='cuda:0', grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder(input_ids = d['input_ids'].cuda().unsqueeze(0), decoder_input_ids = 50264 * torch.ones_like(d['input_ids']).cuda().unsqueeze(0)).end_logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
