# -*- coding: utf-8 -*-
"""Bert with ROUGELoss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xiXKU0DdS2dpvmkGzF76IeKzS9giJA57
"""

# #@title drive._mount
# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools
# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
# !apt-get update -qq 2>&1 > /dev/null
# !apt-get -y install -qq google-drive-ocamlfuse fuse
# from google.colab import auth
# auth.authenticate_user()
# from oauth2client.client import GoogleCredentials
# creds = GoogleCredentials.get_application_default()
# import getpass
# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
# vcode = getpass.getpass()
# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}
# %cd /content
# !mkdir drive
# %cd drive
# !mkdir MyDrive
# %cd ..
# %cd ..
# !google-drive-ocamlfuse /content/drive/MyDrive

# !rm -rf index; git clone https://github.com/cestwc/index.git

# from index.puller import pull_and_unzip
# pull_and_unzip('cnn_dailymail_snippet_tokenized')

# !pip install transformers >/dev/null
# !pip install datasets >/dev/null
# !rm -rf Differentiable-ROUGE-score; git clone https://github.com/cestwc/Differentiable-ROUGE-score.git

import sys
sys.path.append('Differentiable-ROUGE-score')
from trainer import RougeTrainer
# from losses import ROUGELoss
# sys.path.pop()

from datasets import load_dataset, load_from_disk

cnn_dailymail = load_dataset('ccdv/cnn_dailymail', '3.0.0')

from transformers import BertTokenizerFast, BertForMaskedLM
import torch

tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')
model = BertForMaskedLM.from_pretrained('bert-base-uncased')

def tokenize(e):
    article = tokenizer(e['article'], max_length=512, truncation=True, padding = 'max_length')
    article['labels'] = tokenizer(e['highlights'], max_length=128, truncation=True, padding = 'max_length')['input_ids']
    
    return article

cnn_dailymail_tokenized = cnn_dailymail.map(tokenize, batched=True)

cnn_dailymail_tokenized.set_format(type='torch', columns=['input_ids','labels', 'attention_mask'])

print(f"Number of training examples: {len(cnn_dailymail_tokenized['train'])}")
print(f"Number of validation examples: {len(cnn_dailymail_tokenized['validation'])}")
print(f"Number of testing examples: {len(cnn_dailymail_tokenized['test'])}")

import torch
import torch.nn.functional as F

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f'The summarizer has {count_parameters(model):,} trainable parameters')

# drivePath = '/content/drive/MyDrive/Colab Notebooks/orange/'
# drivePath = ''

from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir= 'Bert',
    overwrite_output_dir=True,
    num_train_epochs=1,
    max_steps = 70_000,
    per_device_train_batch_size=8,
    save_steps=5_000,
    save_total_limit=20,
    prediction_loss_only=True,
    # learning_rate=3e-4,
    # logging_steps = 2
)

trainer = RougeTrainer(
    model = model,
    args = training_args,
    train_dataset = cnn_dailymail_tokenized['train'].shuffle(1234),
    eval_dataset = cnn_dailymail_tokenized['validation'],
    # data_collator = collate,
)

trainer.train(resume_from_checkpoint = False)

trainer.evaluate()